{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPm9NEG7udE8EdoEAvqzkpI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuj0630/Catholic_Regacy/blob/main/attention_is_all_you_need_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLNimPKyqGVL",
        "outputId": "474a6fb7-15cd-472b-ede5-3eeffbff71cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.6.0) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.6.0) (4.64.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchtext==0.6.0) (1.13.1+cu116)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.6.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.6.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.6.0) (1.26.14)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.1\n",
            "    Uninstalling torchtext-0.14.1:\n",
            "      Successfully uninstalled torchtext-0.14.1\n",
            "Successfully installed sentencepiece-0.1.97 torchtext-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data preprocessing"
      ],
      "metadata": {
        "id": "Z86h3uXTqZ10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> spaCy 라이브러리 : 문장의 토큰화, 태깅 등의 전처리 기능을 위한 라이브러리"
      ],
      "metadata": {
        "id": "wO26g0N4qely"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "metadata": {
        "id": "LQbu4iIbqT1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "spacy_en = spacy.load('en') #영어 토큰화\n",
        "spacy_de = spacy.load('de') #독일어 토큰화화"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "lO6-n5X7qvD1",
        "outputId": "e1faf49c-1620-4e7d-dd42-bd0a16895847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-776d760d26fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mspacy_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#영어 토큰화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mspacy_de\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'de'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#독일어 토큰화화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m     return util.load_model(\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = spacy_en.tokenizer(\"i am a graduate student.\")\n",
        "\n",
        "for i, token in enumerate(tokenized):\n",
        "  print(f\"인덱스 {i}: {token.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "fXxgodojq3p3",
        "outputId": "9667cb16-59b8-4569-b2dd-57ffb317dffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-64566109143c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i am a graduate student.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"인덱스 {i}: {token.text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'spacy_en' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "영어 및 독일어 토큰화 함수 정의"
      ],
      "metadata": {
        "id": "10_EXDQxrrK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenized_de(text):\n",
        "  return [token.text for token in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenized_en(text):\n",
        "  return [token.text for token in spacy_en.tokenizer(text)]"
      ],
      "metadata": {
        "id": "IuIkqawMrY10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 필드 라이브러리를 이용해 데이터셋에 대한 구체적인 전처리 내용을 명시합니다.\n",
        "> seq2seq 모델과는 다르게 batch_first 속성의 값을 true로 설정합니다."
      ],
      "metadata": {
        "id": "OmlSkqawruMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "SRC = Field(tokenize=tokenize_de, init_token=\"\", eos_token=\"\", lower=True, batch_first=True)\n",
        "SRC = Field(tokenize=tokenize_en, init_token=\"\", eos_token=\"\", lower=True, batch_first=True)"
      ],
      "metadata": {
        "id": "jE0EY9V9rp0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "대표적인 영어_독어 번역 데이터셋인 Multi30k를 불러옵니다."
      ],
      "metadata": {
        "id": "aGDxwJhBsR55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import Multi30k\n",
        "\n",
        "train_dataset, valid_dataset, test_dataset = Multi30k.splits(exts=(\".de\", \".en\"), fields=(SRC, TRG))"
      ],
      "metadata": {
        "id": "RbfxSfPisRVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"학습 데이터셋(training dataset) 크기: {len(train_dataset.examples)}개\")\n",
        "print(f\"평가 데이터셋(validation dataset) 크기: {len(valid_dataset.examples)}개\")\n",
        "print(f\"테스트 데이터셋(testing dataset) 크기: {len(test_dataset.examples)}개\")"
      ],
      "metadata": {
        "id": "Qf8dYjWZs50r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터 중 하나를 선택해 출력\n",
        "print(vars(train_dataset.examples[30])['src'])\n",
        "print(vars(train_dataset.examples[30])['trg'])"
      ],
      "metadata": {
        "id": "g4722mbitAWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "필드 객체의 build_vocab 메서드를 이용해 영어와 독어의 단어 사전을 생성합니다."
      ],
      "metadata": {
        "id": "lQsOVd3qtRJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRC.build_vocab(train_dataset, min_freq=2)\n",
        "TRG.build_vocab(train_dataset, min_freq=2)\n",
        "\n",
        "print(f\"len(SRC): {len(SRC.vocab)}\")\n",
        "print(f\"len(TRG): {len(TRG.vocab)}\")"
      ],
      "metadata": {
        "id": "qJ6MDBOgtI8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(TRG.vocab.stoi[\"abcabc\"]) # 없는 단어: 0\n",
        "print(TRG.vocab.stoi[TRG.pad_token]) # 패딩(padding): 1\n",
        "print(TRG.vocab.stoi[\"\"]) # : 2\n",
        "print(TRG.vocab.stoi[\"\"]) # : 3\n",
        "print(TRG.vocab.stoi[\"hello\"])\n",
        "print(TRG.vocab.stoi[\"world\"])"
      ],
      "metadata": {
        "id": "oDy--4iAttGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   한 문장에 포함된 단어가 순서대로 나열된 상태로 네트워크에 입력되어야 합니다.\n",
        "    *   따라서 하나의 배치에 포함된 문장들이 가지는 단어의 개수가 유사하도록 만들면 좋습니다.\n",
        "    *   이를 위해 bucketiterator를 사용합니다.\n",
        "    *   batch_size : 128\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qj9-cf43u6Wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    train_dataset, valid_dataset, test_dataset),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "F-zFPSqkvUdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(train_iterator):\n",
        "  src = batch.src\n",
        "  src = batch.trg\n",
        "\n",
        "  print(f\"첫 번째 배치 크기: {src.shape}\")\n",
        "\n",
        "  # 현재 배치에 있는 하나의 문장에 포함된 정보 출력\n",
        "  for i in range(src.shape[1]):\n",
        "    print(f\"인덱스 {i}: {src[0][i]. item()}\") # 여기에서는 [Seq_num, Seq_len]\n",
        "\n",
        "  # 첫 번째 배치만 확인\n",
        "  break  "
      ],
      "metadata": {
        "id": "7tVuFqV7v7RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Head Attention 아키텍처"
      ],
      "metadata": {
        "id": "rD5a97fjwyVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 어텐션(attention)은 세 가지 요소를 입력으로 받습니다.\n",
        "\n",
        ">> 쿼리(queries), 키(keys), 값(values)\n",
        "\n",
        ">> 현재 구현에서는 Query, Key, Value의 차원이 모두 같습니다.\n",
        "\n",
        "> 하이퍼 파라미터(hyperparameter)\n",
        "\n",
        ">> hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
        "\n",
        ">> n_heads: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "\n",
        ">> dropout_ratio: 드롭아웃(dropout) 비율\n"
      ],
      "metadata": {
        "id": "J5ultG-tw3lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "  def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n",
        "    super(). __Init__()\n",
        "\n",
        "    assert hidden_dim % n_heads == 0\n",
        "\n",
        "    self.hidden_dim = hidden_dim #임베딩 차원\n",
        "    self.n_heads = n_heads #헤드의 개수 : 서로 다른 어텐션 컨셉의 수\n",
        "    self.head_dim = hidden_dim // n_heads #각 헤드에서의 임베딩 차원\n",
        "\n",
        "    self.fc_q = nn.Linear(hidden_dim, hidden_dim) # Query 값에 적용될 FC 레이어\n",
        "    self.fc_k = nn.Linear(hidden_dim, hidden_dim) # Key 값에 적용될 FC 레이어\n",
        "    self.fc_v = nn.Linear(hidden_dim, hidden_dim) # Value 값에 적용될 FC 레이어\n",
        "\n",
        "    self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "  def forward(self, query, key, value, mask = None):\n",
        "\n",
        "    batch_size = query.shape[0]\n",
        "\n",
        "    #query: [batch_size, query_len, hidden_dim]\n",
        "    #key: [batch_size, key_len, hidden_dim]\n",
        "    #value: [batch_size, value_len, hidden_dim]\n",
        "    Q = self.fc_q(query)\n",
        "    K = self.fc_q(key)\n",
        "    V = self.fc_q(value)\n",
        "\n",
        "    #query: [batch_size, query_len, hidden_dim]\n",
        "    #key: [batch_size, key_len, hidden_dim]\n",
        "    #value: [batch_size, value_len, hidden_dim]\n",
        "\n",
        "    # hidden_dim → n_heads X head_dim 형태로 변형\n",
        "    # n_heads(h)개의 서로 다른 어텐션(attention) 컨셉을 학습하도록 유도\n",
        "    Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "    K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "    V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "    #query: [batch_size, n_heads, query_len, hidden_dim]\n",
        "    #key: [batch_size, n_heads, key_len, hidden_dim]\n",
        "    #value: [batch_size, n_heads, value_len, hidden_dim]\n",
        "\n",
        "    # Attention Energy 계산\n",
        "    energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "\n",
        "    # energy: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "    # 마스크(mask)를 사용하는 경우\n",
        "    if mask is not None:\n",
        "        # 마스크(mask) 값이 0인 부분을 -1e10으로 채우기\n",
        "        energy = energy.masked_fill(mask==0, -1e10)\n",
        "\n",
        "    # 어텐션(attention) 스코어 계산: 각 단어에 대한 확률 값\n",
        "    attention = torch.softmax(energy, dim=-1)\n",
        "\n",
        "    # attention: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "    # 여기에서 Scaled Dot-Product Attention을 계산\n",
        "    x = torch.matmul(self.dropout(attention), V)\n",
        "\n",
        "    # x: [batch_size, n_heads, query_len, head_dim]\n",
        "\n",
        "    x = x.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "    # x: [batch_size, query_len, n_heads, head_dim]\n",
        "\n",
        "    x = x.view(batch_size, -1, self.hidden_dim)\n",
        "\n",
        "    # x: [batch_size, query_len, hidden_dim]\n",
        "\n",
        "    x = self.fc_o(x)\n",
        "\n",
        "    # x: [batch_size, query_len, hidden_dim]\n",
        "\n",
        "    return x, attention\n",
        "         "
      ],
      "metadata": {
        "id": "2h5lnMOmw1Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# position_wise Feedforward 아키텍처"
      ],
      "metadata": {
        "id": "6aouGGDn9fRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   입력과 출력의 차원이 동일합니다.\n",
        "*   하이퍼 파라미터\n",
        "   *   hidden_dim : 하나의 단어에 대한 임베딩 차원\n",
        "   *   pf_dim : Feedforward 레이어에서의 내부 임베딩 차원\n",
        "   *   dropout_ratio : 드롭아웃\n"
      ],
      "metadata": {
        "id": "6hOJY_b89k8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedforward(nn.Module):\n",
        "  def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
        "    super().__init__()\n",
        "\n",
        "    self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n",
        "    self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n",
        "\n",
        "    self.dropout - nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # x : [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "    x = self.dropout(torch.relu(self.fc_1(x)))   \n",
        "\n",
        "    # x : [batch_size, seq_len, pf_dim]\n",
        "\n",
        "    x = self.fc_2(x)\n",
        "\n",
        "    # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "L5ufFKkZ9YyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 인코더 레이어 아키텍처"
      ],
      "metadata": {
        "id": "xDnoRqVG_Lyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   하나의 인코더  레이어에 대해 정의합니다.\n",
        "    *   입력과 출력의 차원이 같습니다.\n",
        "    *   이러한 특징을 이용해 트랜스포머의 인코더는 인코더 레이어를 여러번 중첩해 사용합니다.\n",
        "*   하이퍼 파라미터\n",
        "    *   hidden_dim : 하나의 단어에 대한 임베딩 차원\n",
        "    *   n_heads : 헤드의 개수=scaled dot_product attention\n",
        "    *   pf_dim : Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    *   dropout_ratio : 드롭아웃 비율\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sipN2cSN_Po7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 하나의 임베딩이 복제되어 Query, Key, Value로 입력되는 방식\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        # self attention\n",
        "        # 필요한 경우 마스크(mask) 행렬을 이용하여 어텐션(attention)할 단어를 조절 가능\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # position-wise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        return src"
      ],
      "metadata": {
        "id": "larL9JeD-4as"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 디코더 아키텍처"
      ],
      "metadata": {
        "id": "i_Ybp46qMyC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 디코더 아키텍처를 정의합니다.\n",
        "\n",
        "하이퍼 파라미터(hyperparameter)\n",
        "\n",
        "output_dim: 하나의 단어에 대한 원 핫 인코딩 차원\n",
        "\n",
        "hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
        "\n",
        "n_layers: 내부적으로 사용할 인코더 레이어의 개수\n",
        "\n",
        "n_heads: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "\n",
        "pf_dim: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "\n",
        "dropout_ratio: 드롭아웃(dropout) 비율\n",
        "\n",
        "max_length: 문장 내 최대 단어 개수\n",
        "\n",
        "> 원본 논문과는 다르게 위치 임베딩(positional embedding)을 학습하는 형태로 구현합니다.\n",
        "\n",
        "> BERT와 같은 모던 트랜스포머 아키텍처에서 사용되는 방식입니다.\n",
        "\n",
        "> Seq2Seq과는 마찬가지로 실제로 추론(inference) 시기에서는 디코더를 반복적으로 넣을 필요가 있습니다.\n",
        "> 학습(training) 시기에서는 한 번에 출력 문장을 구해 학습할 수 있습니다.\n",
        "\n",
        "> 소스 문장의 <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정합니다.\n",
        "\n",
        "> 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용합니다."
      ],
      "metadata": {
        "id": "hpbLBEirM0jE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        # trg: [batch_size, trg_len]\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "        # trg_mask: [batch_size, trg_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        # pos: [batch_size, trg_len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            # 소스 마스크와 타겟 마스크 모두 사용\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "\n",
        "        return output, attention\n"
      ],
      "metadata": {
        "id": "y7BPabGDMzqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transformer 아키텍처"
      ],
      "metadata": {
        "id": "8VcA5ANiGq-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "최종적인 전체 트랜스포머 모델을 정의합니다.\n",
        "\n",
        "입력이 들어왔을 때 앞서 정의한 인코더와 디코더를 거쳐 출력 문장을 생성합니다."
      ],
      "metadata": {
        "id": "M36Krb0SGuIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn, Module):\n",
        "  def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_pad_idx = src_pad_idx\n",
        "    self.trg_pad_idx = trg_pad_idx\n",
        "    self.device = device\n",
        "\n",
        "  # 소스 문장의 토큰에 대하여 마스크 값을 0으로 설정\n",
        "  def make_src_mask(self, src):\n",
        "    # src : [batch_size, src_len]\n",
        "    src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    # src_mask: [batch_size, 1, 1, src_len]\n",
        "\n",
        "    return src\n",
        "  def make_trg_mask(self, trg):\n",
        "    # trg:[batch_size, trg_len]\n",
        "    trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    # trg_pad_mask: [batch_size, 1, 1, trg_len]\n",
        "    trg_len = trg.shape[1]\n",
        "    trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "    # trg_sub_mask: [trg_len, trg_len\n",
        "    trg_mask = trg_pad_mask & trg_sub_mask\n",
        "    # trg_mask: [batch_size, 1, trg_len, trg_len\n",
        "    return trg_mask\n",
        "\n",
        "  def forward(self, src, trg):\n",
        "\n",
        "    #src : [batch_size, src_len]\n",
        "    #trg : [batch_size, trg_len]\n",
        "\n",
        "    src_mask = self.make_src_mask(src)\n",
        "    trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "    # src_mask: [batch_size, 1, 1, src_len]\n",
        "    # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "    enc_src = self.encoder(src, src_mask)\n",
        "\n",
        "    # enc_src : [batch_size, src_len, hidden_dim]\n",
        "\n",
        "    output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "    # output: [batch_size, trg_len, output_dim]\n",
        "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "    return output, attention"
      ],
      "metadata": {
        "id": "Mpn2vJ18Gp0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HIDDEN_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1"
      ],
      "metadata": {
        "id": "ufSB1jRpJUMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "enc = Encoder(INPUT_DIM, HIDDEN_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
        "dec = Decoder(OUTPUT_DIM, HIDDEN_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
        "\n",
        "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "8wt2w9oxJWg1",
        "outputId": "0a8c8404-4948-46df-e016-57ea53e4008d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-58d35c01ddbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSRC_PAD_IDX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mTRG_PAD_IDX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTRG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENC_LAYERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENC_HEADS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENC_PF_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENC_DROPOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEC_LAYERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEC_HEADS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEC_PF_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEC_DROPOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SRC' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 가중치 파라미터 초기화"
      ],
      "metadata": {
        "id": "QUDmYLV8KrmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.patameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "id": "E5is2ZmkKCyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights)"
      ],
      "metadata": {
        "id": "WAV2CXJlK60E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   학습 및 평가 함수 정의\n",
        "    *   기본적인 Seq2Seq 모델과 거의 유사하게 작성할 수 있습니다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jhd-ghEkLABM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Adam optimizer로 학습 최적화\n",
        "LEARNING_RATE = 0.0005\n",
        "optimizer = torch.optim.Adam(model.patameters(), lr=LEARNING_RATE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "t324AUizK_Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습(train) 함수\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train() # 학습 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # 전체 학습 데이터를 확인하며\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 출력 단어의 마지막 인덱스()는 제외\n",
        "        # 입력을 할 때는 부터 시작하도록 처리\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        # output: [배치 크기, trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기, trg_len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        # 출력 단어의 인덱스 0()은 제외\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "        # output: [배치 크기 * trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기 * trg len - 1]\n",
        "\n",
        "        # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward() # 기울기(gradient) 계산\n",
        "\n",
        "        # 기울기(gradient) clipping 진행\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 전체 손실 값 계산\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "romUL82eLgfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train model, evaluate,validate가 뭐가 다른가?"
      ],
      "metadata": {
        "id": "9LEbg24CS8x5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가(evaluate) 함수\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval() # 평가 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # 전체 평가 데이터를 확인하며\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            # 출력 단어의 마지막 인덱스()는 제외\n",
        "            # 입력을 할 때는 부터 시작하도록 처리\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "            # output: [배치 크기, trg_len - 1, output_dim]\n",
        "            # trg: [배치 크기, trg_len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            # 출력 단어의 인덱스 0()은 제외\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            # output: [배치 크기 * trg_len - 1, output_dim]\n",
        "            # trg: [배치 크기 * trg len - 1]\n",
        "\n",
        "            # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            # 전체 손실 값 계산\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "ZJqdYONsS3_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 및 검증 진행"
      ],
      "metadata": {
        "id": "41t83ZhwUeaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "Ai916RTsTMmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "import random\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start_time = time.time()\n",
        "\n",
        "  train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "  valid_lostt = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = best_valid_loss\n",
        "    torch.save(model.state_dict(), 'transformer_german_to_english.pt')\n",
        "\n",
        "  print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
        "  print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "2xjXd92hU1fW",
        "outputId": "169f8a84-9973-402f-b23c-cb43cbba0fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-19d0aad5f2f0>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    for epoch in range(N_EPOCHS):\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모델 저장\n",
        "from google.colab import files\n",
        "\n",
        "files.download('transformer_german_to_english.pt')"
      ],
      "metadata": {
        "id": "_o-byzz0VANs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}